{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *La Main à la Pâte*, Generate Chefs and Recipes\n",
    "*--- WIP ---*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ollama import Client\n",
    "from pydantic import BaseModel\n",
    "from devtools import pprint\n",
    "import json\n",
    "import string\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"\")\n",
    "\n",
    "from datetime import datetime\n",
    "import helper_io as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conf. ollama and select model\n",
    "HOST_LLAMA=os.environ['HOST_LLAMA']\n",
    "LLAMA_MODEL=\"llama3.2\"\n",
    "\n",
    "client = Client(\n",
    "  host=HOST_LLAMA,\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "\n",
    "# Conf. io directories\n",
    "WORKDIR = Path(os.getcwd())\n",
    "DIR_SCHEMAS = Path(WORKDIR.parent, 'json_schemas')\n",
    "DIR_OUTPUT = Path(WORKDIR.parent, 'out')\n",
    "DIR_PROMPTS = Path(WORKDIR.parent, 'prompts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "To use Ollama's structured output, the LLM-model answer to the prompt is constrained with a *JSON Schema*, conveniently registered in Python with a Pydantic Model.\n",
    "The *JSON schemas* are registered in the `DIR_MODELS` directory. We provide ios functions for saving/loading schemas in `src/helper_io.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples of models\n",
    "class Chef(BaseModel):\n",
    "    familyName:     str\n",
    "    givenName:      str\n",
    "    alternateName:  str\n",
    "    birthDate:      str # Problem with pydantic datetime declaration\n",
    "    gender:         str\n",
    "    description:    str\n",
    "    homeLocation:   str \n",
    "    image:          str \n",
    "    prefCuisine:    list[str] \n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    id_chef_creator:        str\n",
    "    name:                   str\n",
    "    recipeIngredients:      list[str]\n",
    "    recipeYield:            str\n",
    "    recipeInstructions:     list[str]\n",
    "    prepTime:               int\n",
    "    cookTime:               int\n",
    "    description:            str\n",
    "    image:                  str\n",
    "    recipeCategory:         str\n",
    "    recipeCuisine:          list[str]\n",
    "    keywords:               list[str]\n",
    "\n",
    "\n",
    "# # Save an existing model\n",
    "# helper.save_pydantic_model_as_jsonschema(directory_schema=DIR_SCHEMAS, schema_pydmodel=Chef)\n",
    "# helper.save_pydantic_model_as_jsonschema(directory_schema=DIR_SCHEMAS, schema_pydmodel=Recipe)\n",
    "\n",
    "# Load an existing model\n",
    "# Animal = helper.load_jsonschema_to_pydantic_model(json.loads(Path(WORKDIR.parent, 'json_schemas', 'Animal.json').read_text()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "*--- WIP ---*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a prompt\n",
    "# helper.save_pydantic_model(directory_models: str|Path, model: BaseModel)\n",
    "\n",
    "# Load an existing prompt\n",
    "# helper.load_pydantic_model(directory_models: str|Path, model: BaseModel) -> BaseModel\n",
    "\n",
    "current_chefschema=Chef\n",
    "current_chefprompt_name=\"Chef-b102\"\n",
    "current_chefprompt = \"\"\"You are the editor-in-chief of a famous international restaurant and cooking guide, open to all audiences, from the most modest to the most gastronomic (for example traditional french cuisine, chinese street food or english bistronomy).\n",
    "You want to exhibit one of you favorite chief in the pages of your next issue. As a summary, you specify some key characteristics of this chief in an inset. The outline of these characteristics are:\n",
    "- familyName: Family name, the last name of a person. \n",
    "- givenName: Given name, the first name of a person. \n",
    "- alternateName: An alias for the chef. \n",
    "- birthDate: Date of birth, should be provided in the following ISO 8601 format: 'YYYY-MM-DD'. \n",
    "- gender: Gender of something, typically a Person, but possibly also fictional characters, animals, etc\n",
    "- homeLocation: An indication of a person' location\n",
    "- description: A short bio of the chef\n",
    "- image: should be the alternative description for the chef image.\n",
    "- prefCuisine: Preferred cuisine types (for example, French, Vietnamian, Bistronomy, Street-Food)\n",
    "\n",
    "Invent a chief, as a fictional but realistic character. \n",
    "In this chat, you may be asked to invent different chiefs, they shall be as diverse as possible and from all social backgrounds. \n",
    "\"\"\"\n",
    "\n",
    "# helper.save_prompt(directory_prompt=DIR_PROMPTS, prompt=current_chefprompt, prompt_name=current_chefprompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_recipeschema=Recipe\n",
    "current_recipeprompt_name=\"Recipe-b200p\"\n",
    "current_recipeprompt = \"\"\"\n",
    "You are a one of the chefs showcased in a famous international restaurant and cooking guide, open to all audiences, from the most modest to the most gastronomic. Here are some of your traits:\n",
    "- name: {givenName} {familyName}. \n",
    "- birthDate: {birthDate}\n",
    "- gender: {gender}\n",
    "- homeLocation: {homeLocation}\n",
    "- description: {description}\n",
    "- preferred cuisine types: {prefCuisine}\n",
    "\n",
    "You want to share a dish that is meaningful to you. You indicate the characteristics of the recipes, the ingredients and the steps in an orderly fashion:\n",
    "- id_chef_creator: shall be your '{givenName} {familyName}'\n",
    "- name: The name of the dish\n",
    "- recipeIngredient: The necessary ingredients and their quantities used in the recipe.\n",
    "- recipeYield: The quantity produced by the recipe, if applicable. Specify the number of servings produced from this recipe with just a number.\n",
    "- recipeInstructions: The steps to make the dish.\n",
    "- prepTime: The length of time it takes to prepare ingredients and workspace for the dish\n",
    "- cookTime: The time it takes to actually cook the dish\n",
    "- description: A short summary describing the dish.\n",
    "- image: should be the alternative description for the dish image.\n",
    "- recipeCategory: The type of meal or course your recipe is about. For example: \"dinner\", \"main course\", or \"dessert, snack\".\n",
    "- recipeCuisine: The region associated with your recipe. For example, \"French\", Mediterranean\", or \"American\".\n",
    "- keywords: Other terms for your recipe such as the season (\"summer\"), the holiday (\"Halloween\"), or other descriptors (\"quick\", \"easy\", \"authentic\").\n",
    "\n",
    "Invent a recipe, {givenName} {familyName}. In this chat, you may be asked to invent different recipes, they shall be as diverse as possible, include main dishes, snacks, appetizers, drinks, deserts, etc... \n",
    "\"\"\"\n",
    "# helper.save_prompt(directory_prompt=DIR_PROMPTS, prompt=current_recipeprompt, prompt_name=current_recipeprompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.chat(\n",
    "#   messages=[\n",
    "#     {\n",
    "#       'role': 'user',\n",
    "#       'content': current_chefprompt,\n",
    "#     }\n",
    "#   ],\n",
    "#   model=LLAMA_MODEL,\n",
    "#   format=current_chefschema.model_json_schema(),\n",
    "# )\n",
    "# display(response)\n",
    "\n",
    "# out = current_chefschema.model_validate_json(response.message.content)\n",
    "# pprint(out)\n",
    "\n",
    "# current_recipeprompt.format(**out.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate one-to-many Chefs and Recipes\n",
    "*--- WIP ---*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "class GroupOfChefs(BaseModel):\n",
    "    chefs:          list[Chef]\n",
    "    motivation:      str\n",
    "\n",
    "class BundleOfRecipes(BaseModel):\n",
    "    recipes:        list[Recipe]\n",
    "    motivation:     str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SingleGroups prompts\n",
    "current_groupchefschema=GroupOfChefs\n",
    "current_groupchefprompt_name=\"GroupOfChefs-b101\"\n",
    "current_groupchefprompt = \"\"\"You are the editor-in-chief of a famous international restaurant and cooking guide, open to all audiences, from the most modest to the most gastronomic, with any socio-cultural background.\n",
    "You want to exhibit one of you favorite chief in the pages of your next issue. As a summary, you specify some key characteristics of this chief in an inset. The outline of these characteristics are:\n",
    "- familyName: Family name, the last name of a person. \n",
    "- givenName: Given name, the first name of a person. \n",
    "- alternateName: An alias for the chef. \n",
    "- birthDate: Date of birth, should be provided in the following ISO 8601 format: 'YYYY-MM-DD'. \n",
    "- gender: Gender of something, typically a Person, but possibly also fictional characters, animals, etc\n",
    "- homeLocation: An indication of a person' location\n",
    "- description: A short bio of the chef\n",
    "- image: should be the alternative description for the chef image.\n",
    "- prefCuisine: Preferred cuisine types (for example, French, Vietnamian, Bistronomy, Street-Food)\n",
    "\n",
    "Invent {nb_chef} chiefs, as fictional but realistic characters. This group of chiefs shall be as diverse as possible, but complementary. The choice of these {nb_chef} chiefs shall be motivated by a short description, in the GroupOfChefs motivation field.\n",
    "\"\"\"\n",
    "\n",
    "# helper.save_prompt(directory_prompt=DIR_PROMPTS, prompt=current_groupchefprompt, prompt_name=current_groupchefprompt_name)\n",
    "\n",
    "current_bundlerecipeschema=BundleOfRecipes\n",
    "current_bundlerecipeprompt_name=\"BundleOfRecipes-b100\"\n",
    "current_bundlerecipeprompt = \"\"\"You are a one of the chefs showcased in a famous international restaurant and cooking guide, open to all audiences, from the most modest to the most gastronomic. Here are some of your traits:\n",
    "- name: {givenName} {familyName}. \n",
    "- birthDate: {birthDate}\n",
    "- gender: {gender}\n",
    "- homeLocation: {homeLocation}\n",
    "- description: {description}\n",
    "- preferred cuisine types: {prefCuisine}\n",
    "\n",
    "You want to share a dish that is meaningful to you. You indicate the characteristics of the recipes, the ingredients and the steps in an orderly fashion:\n",
    "- id_chef_creator: shall be your '{givenName} {familyName}'\n",
    "- name: The name of the dish\n",
    "- recipeIngredient: The necessary ingredients and their quantities used in the recipe.\n",
    "- recipeYield: The quantity produced by the recipe, if applicable. Specify the number of servings produced from this recipe with just a number.\n",
    "- recipeInstructions: The steps to make the dish.\n",
    "- prepTime: The length of time it takes to prepare ingredients and workspace for the dish\n",
    "- cookTime: The time it takes to actually cook the dish\n",
    "- description: A short summary describing the dish.\n",
    "- image: should be the alternative description for the dish image.\n",
    "- recipeCategory: The type of meal or course your recipe is about. For example: \"dinner\", \"main course\", or \"dessert, snack\".\n",
    "- recipeCuisine: The region associated with your recipe. For example, \"French\", Mediterranean\", or \"American\".\n",
    "- keywords: Other terms for your recipe such as the season (\"summer\"), the holiday (\"Halloween\"), or other descriptors (\"quick\", \"easy\", \"authentic\").\n",
    "\n",
    "\n",
    "Invent the {nb_recipe} key recipes of {givenName} {familyName}. The choice of these {nb_recipe} recipes shall be as diverse as possible, include main dishes, snacks, appetizers, drinks, deserts, etc... \n",
    "The choice of these {nb_recipe} recipes shall be motivated by a short description, in the BundleOfRecipes motivation field.\n",
    "\"\"\"\n",
    "\n",
    "# helper.save_prompt(directory_prompt=DIR_PROMPTS, prompt=current_bundlerecipeprompt, prompt_name=current_bundlerecipeprompt_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_chef=2\n",
    "# nb_recipe=2\n",
    "\n",
    "# response = client.chat(\n",
    "#   messages=[\n",
    "#     {\n",
    "#       'role': 'user',\n",
    "#       'content': current_groupchefprompt.format(nb_chef=nb_chef),\n",
    "#     }\n",
    "#   ],\n",
    "#   model=LLAMA_MODEL,\n",
    "#   format=current_groupchefschema.model_json_schema(),\n",
    "# )\n",
    "# display(response)\n",
    "\n",
    "# out_chef = current_groupchefschema.model_validate_json(response.message.content)\n",
    "# # pprint(out_chef)\n",
    "\n",
    "# logger.info(f\"Motivation for the groupe of chefs{out_chef.motivation}\")\n",
    "# for i in range(nb_chef):\n",
    "#     logger.info(f\"Saving new chef {out_chef.chefs[i].familyName} {out_chef.chefs[i].givenName} with cuisines {out_chef.chefs[i].prefCuisine}\")\n",
    "#     helper.save_structured_output(output=out_chef.chefs[i].model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_chefprompt_name, llm_model=LLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_chef_to_recipe_prompt = out_chef.chefs[1].model_dump() | {'nb_recipe': nb_recipe}\n",
    "# out_chef_to_recipe_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_recipes=2\n",
    "# response = client.chat(\n",
    "#   messages=[\n",
    "#     {\n",
    "#       'role': 'user',\n",
    "#       'content': current_bundlerecipeprompt.format(**out_chef_to_recipe_prompt),\n",
    "#     }\n",
    "#   ],\n",
    "#   model=LLAMA_MODEL,\n",
    "#   format=current_bundlerecipeschema.model_json_schema(),\n",
    "# )\n",
    "# display(response)\n",
    "\n",
    "# out_recipes = current_bundlerecipeschema.model_validate_json(response.message.content)\n",
    "\n",
    "# logger.info(f\"Motivation for the groupe of chefs{out_recipes.motivation}\")\n",
    "# for i in range(nb_chef):\n",
    "#     logger.info(f\"Saving new recipe {out_recipes.recipes[i].name} with cuisines {out_recipes.recipes[i].recipeCuisine}\")\n",
    "#     helper.save_structured_output(output=out_recipes.recipes[i].model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_recipeprompt_name, llm_model=LLAMA_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_bundlerecipeprompt.format(**out_chef_to_recipe_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Saving new chef Kumar Rajesh with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_225730_62c-Chef-b102-llama3.2.json\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Motivation for the groupe of chefs[\"Personal Project\", \"Recipe Collection\"]\n",
      "INFO:root:Saving new recipe for Rajesh Kumar, Tandoori Chicken Tikka Masala with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_b45-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Rajesh Kumar, Spiced Chai Tea with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_924-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Rajesh Kumar, Kabuli Chicken Biryani with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_ba7-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Rajesh Kumar, Gulab Jamun with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_983-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Rajesh Kumar, Pav Bhaji with cuisines ['Indian']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_ae6-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new chef Lopez Ana with cuisines ['Cuban', 'Mexican']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230008_b7e-Chef-b102-llama3.2.json\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Motivation for the groupe of chefsTo share my passion for Mexican cuisine and culture with the world.\n",
      "INFO:root:Saving new recipe for Ana Lopez, Lechon Asado con Mojo with cuisines ['Cuban']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230216_1bd-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Ana Lopez, Chiles Rellenos con Queso with cuisines ['Mexican']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230216_16f-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Ana Lopez, Agua de Jamaica con Lime y Mint with cuisines ['Mexican']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230216_96e-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Ana Lopez, Tres Leches Cake with Coconut Flakes with cuisines ['Mexican']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230216_76e-Recipe-b200p-llama3.2.json\n",
      "INFO:root:Saving new recipe for Ana Lopez, Chiles en Nogada con Picadillo with cuisines ['Mexican']\n",
      "INFO:helper_io:Saving output c:\\_Etudes\\25_Main_Patte\\lamachef\\out\\250120_230216_8d3-Recipe-b200p-llama3.2.json\n"
     ]
    }
   ],
   "source": [
    "nb_chef=2\n",
    "nb_recipe=5\n",
    "\n",
    "response = client.chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': current_groupchefprompt.format(nb_chef=nb_chef),\n",
    "    }\n",
    "  ],\n",
    "  model=LLAMA_MODEL,\n",
    "  format=current_groupchefschema.model_json_schema(),\n",
    ")\n",
    "# display(response)\n",
    "\n",
    "out_chef = current_groupchefschema.model_validate_json(response.message.content)\n",
    "# pprint(out_chef)\n",
    "\n",
    "# logger.info(f\"Motivation for the groupe of chefs{out_chef.motivation}\")\n",
    "for i in range(nb_chef):\n",
    "    current_chef = out_chef.chefs[i]\n",
    "    current_chef_to_recipe_prompt = current_chef.model_dump() | {'nb_recipe': nb_recipe}\n",
    "\n",
    "    logger.info(f\"Saving new chef {current_chef.familyName} {current_chef.givenName} with cuisines {current_chef.prefCuisine}\")\n",
    "    helper.save_structured_output(output=current_chef.model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_chefprompt_name, llm_model=LLAMA_MODEL)\n",
    "\n",
    "\n",
    "\n",
    "    response2 = client.chat(\n",
    "    messages=[\n",
    "        {\n",
    "        'role': 'user',\n",
    "        'content': current_bundlerecipeprompt.format(**current_chef_to_recipe_prompt),\n",
    "        }\n",
    "    ],\n",
    "    model=LLAMA_MODEL,\n",
    "    format=current_bundlerecipeschema.model_json_schema(),\n",
    "    )\n",
    "    # display(response2)\n",
    "\n",
    "    out_recipes = current_bundlerecipeschema.model_validate_json(response2.message.content)\n",
    "\n",
    "    logger.info(f\"Motivation for the groupe of chefs{out_recipes.motivation}\")\n",
    "    for i in range(nb_recipe):\n",
    "        logger.info(f\"Saving new recipe for {out_recipes.recipes[i].id_chef_creator}, {out_recipes.recipes[i].name} with cuisines {out_recipes.recipes[i].recipeCuisine}\")\n",
    "        helper.save_structured_output(output=out_recipes.recipes[i].model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_recipeprompt_name, llm_model=LLAMA_MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: For ... Each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*n* Chefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     response = client.chat(\n",
    "#     messages=[\n",
    "#         {\n",
    "#         'role': 'user',\n",
    "#         'content': current_chefprompt,\n",
    "#         }\n",
    "#     ],\n",
    "#     model=LLAMA_MODEL,\n",
    "#     format=current_chefschema.model_json_schema(),\n",
    "#     )\n",
    "#     out_chef = current_chefschema.model_validate_json(response.message.content)\n",
    "#     logger.info(f\"Saving new chef {out_chef.familyName} {out_chef.givenName} with cuisines {out_chef.prefCuisine}\")\n",
    "#     helper.save_structured_output(output=out_chef.model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_chefprompt_name, llm_model=LLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*n* chefs with *m* recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    response = client.chat(\n",
    "    messages=[\n",
    "        {\n",
    "        'role': 'user',\n",
    "        'content': current_chefprompt,\n",
    "        }\n",
    "    ],\n",
    "    model=LLAMA_MODEL,\n",
    "    format=current_chefschema.model_json_schema(),\n",
    "    )\n",
    "    out_chef = current_chefschema.model_validate_json(response.message.content)\n",
    "    logger.info(f\"Saving new chef {out_chef.familyName} {out_chef.givenName} with cuisines {out_chef.prefCuisine}\")\n",
    "    helper.save_structured_output(output=out_chef.model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_chefprompt_name, llm_model=LLAMA_MODEL)\n",
    "\n",
    "    for i in range(2):\n",
    "        response2 = client.chat(\n",
    "        messages=[\n",
    "            {\n",
    "            'role': 'user',\n",
    "            'content': current_recipeprompt.format(**out_chef.model_dump()),\n",
    "            }\n",
    "        ],\n",
    "        model=LLAMA_MODEL,\n",
    "        format=current_recipeschema.model_json_schema(),\n",
    "        )\n",
    "        out_recipe = current_recipeschema.model_validate_json(response2.message.content)\n",
    "        logger.info(f\"Saving recipe {out_recipe.name} from chef {out_chef.familyName} {out_chef.givenName} as {out_recipe.recipeCategory}\")\n",
    "        helper.save_structured_output(output=out_recipe.model_dump(), directory_outputs=DIR_OUTPUT, prompt_name=current_recipeprompt_name, llm_model=LLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
